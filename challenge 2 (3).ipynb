{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Machine Learning 2019/2020 - Challenge 2 - 16 December 2019\n",
    "\n",
    "## Rules (read carefully):\n",
    "- This year the results of the two challenges will count 10% and 15% respectively of your final score.\n",
    "- If you work with a group of colleges (max 3 students), please remember your solution must be <b>\"your solution\"</b>, hence provide your individual answers/arguments/opinions/critics;\n",
    "- Students of the same group can share <b>ONLY</b> the code.\n",
    "- Mail your solution (a <b>jupyter notebook</b>) only to stefano.faralli@unitelmasapienza.it before the 1:59 PM of the 19 December 2019 (Rome Berlin time);\n",
    "- The subject of your email must be: \"[Challenge_2_solution] NAME - SURNAME - MATRICOLA.\"\n",
    "- Double check the subject of your email and the attachments;\n",
    "- In case you want to compress the attachment, <b>USE ONLY STANDARD ZIP compression</b>;\n",
    "- <b>Please sumbit ONLY the notebook with SAVED OUTPUTS!</b>\n",
    "- The physical attendance to the lab is not mandatory, you can work from a remote place by following the identical rules.\n",
    "- Your solution might be considered as the \"copy\" of others solutions, in that specific case the assigned score will be the result of the proposed solution divided by the number of \"too much similar\" solutions. If you share the code with the components of your \"group\" please comment the code and answer the questions by yourself.\n",
    "\n",
    "- Monday 16 December, I will share the necessary key to unzip the content of the provided challenge material (I will also send a message on the Google group).\n",
    "- To unzip the content of the zip you will use the above key\n",
    "- Then read carefully all the part of the jupyter notebook and fill all mandatory fields.\n",
    "- <b>Don't write \"personal\" emails</b> to Stefano Faralli, but please <b>use the google group</b> I will reply until 12 AM of 17 December 2019 <b>(strict deadline)</b>. \n",
    "- <b>solutions (and correspondig points) are evaluated mainly on your thoughts/comments/opinions</b> hence, please use the provided corresponding \"YOUR COMMENTS\" cell</b> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification (Mandatory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "yourNameSurname = 'shadi andishmand'\n",
    "yourMatricolaNumber = '1919010'\n",
    "yourStudentEMAIL = 'andishmand.1919010@studenti.uniroma1.it'\n",
    "yourColleguesNameSurnames=['paolo mazza']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lego Bricks Visual Classification\n",
    "<img src=\"45020_Prod_03.jpg\"/>\n",
    "\n",
    "## Description of the task:\n",
    "<br>\n",
    "devolop a classifier able to classify with a <b>weighted avg F1 score greater than 0.60</b> pictures of Lego bricks taken at different angles.\n",
    "Use Keras and scikit-learn to develop, train and evaluate a CNN with:<br>\n",
    "- Convolutional and Pooling operations<br>  \n",
    "- a dense sub network at the end <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 -  Dataset (max 6/30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1-a  - Load the dataset (3/6 pts)\n",
    "The provided dataset is composed by pictures of Lego bricks, taken at different angles:<br>\n",
    "As an example the following picture:<br>\n",
    "<img src=\"dataset/train/2357 Brick corner 1x2x2/201706171206-0001.png\"/> \n",
    "corresponds to the png file in \"dataset/train/2357 Brick corner 1x2x2/201706171206-0001.png\"\n",
    "- \"201706171206-0001.png\" is the name of the file;\n",
    "- \"2357 Brick corner 1x2x2\" is the label of the Lego brick type;\n",
    "- \"train\" means that this is the portion of the dataset you must use for the training\n",
    "Inside the folder <b>dataset</b> you can find another subfolder <b>validatetest</b>.\n",
    "The content inside of <b>validatetest</b> must be used (after a proper split) for validation during training and for testing during the evaluation.\n",
    "\n",
    "\n",
    "Load the dataset and create: \n",
    "- X_train, y_train from the content in \"dataset/train/\"\n",
    "- X_validate,y_validate,X_test,y_test as a split (20% for validation and 80% for test) of the content in \"dataset/validatetest/\"\n",
    "\n",
    "<b>Tips:</b>\n",
    "- you can use CV2 or matplotlib to load pictures\n",
    "- check the file you are loading is ending with \".png\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPictures(path):\n",
    "  for _,dirs,_ in os.walk(path):\n",
    "    X = []\n",
    "    y = []\n",
    "    for dir in dirs:\n",
    "        for _,_,files in os.walk(path+dir+\"/\"):\n",
    "            for file in files:\n",
    "                if file.find('.png')<0:\n",
    "                       continue     \n",
    "                img = cv2.imread(path+dir+\"/\"+file)\n",
    "                X.append(img)\n",
    "                y.append(dir)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = loadPictures('dataset/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = loadPictures('dataset/validationandtest/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# your comments: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# part 1-a - load data set\n",
    "in this part there is 4 blocks of code.\n",
    "in the first part the useful libraries is imporetd:\n",
    "first library is matplotlib which is used for heatmap plot in the 4th part.this library is useful for plotting 2D , os for directory cv2 for image reading and sklearn.model_selection for spliting dataset into two part.\n",
    "\n",
    "in the second block LOADPICTURE function is defined to give hte images directory.in that os which is used for walk function which is a function that creates a tuple of values (current_path, directories in current_path, files in current_path) which here we just need dirs in first for then in second for we go into files and try to find all imges with png extension.\n",
    "then we use imread from opencv library which load image from a specific file.in this function we pass the (path) to it and then we use this to load our data set.\n",
    "then we call this function to load images into RAM and use them for training and evaluating.the final folder contain labeles and pictures \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1-b Dataset  preprocessing (3/6 pts max)\n",
    "Since you are using the dataset for a classification task using Keras API you will need to perform some dataset tranformations:<br>\n",
    "1) tranform all the images into grayscale having a final shape of (dim,dim,1)  dim<200;<br>\n",
    "<img src=\"info.png\">\n",
    "2) encode properly the target features for train, test and validation<br>\n",
    "\n",
    "<b>Tips:</b>\n",
    "- you can use CV2 and numpy to tranform and reshape the pictures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part1-b data preprocessing\n",
    "in this part we did preprocessing the data which is really important before feeding it into our model.i did preprocessing before spliting my dataset to train and test to avoid doing a similiar work again. \n",
    "\n",
    "first block import pandas library for using get dummies and then numpy for some functions like reshape in first block.we load train and test dataset in 3 dimensions.if we had really big data set we should try another ways to load data set and i tried first another way to load data step by step in memory by generator but it was slow in my pc so i changed it to this way since the data set was small.\n",
    "\n",
    "second and third block do similar things for train dataset and test dataset: \n",
    "we do resizing with a specific scale ( i use this scale since with smaller sacle the picture is getting fade and resouloution and edges of images decrease and it get worse for CNN to classify legoes corectly) and making small each image and then we change the image to gray by using \"resize and cvtcolor\" from opencv .as you know colorful images have 3 channel RGB which with converting them to gray we reduced it to 1 channel.After convert to gray we use the minmax scaling to have pixel values in range [0,1].\n",
    "\n",
    "in 4th block i reshaped the dataset and add 1dimension to it since we need 4 dimension for CNN.\n",
    "in 5th block i used get_dummies function which help me to make one feature for each different values that i have in target function and we need it since we wanted to use softmax in the output layer and output is 16 values array and in this way we have a 16 values array that one of them is 1 that it is the predicted class so with get dummies i transformed it to modify my categories as i want.\n",
    "\n",
    "in last part i splited data to test and train which i specified 80% is for test and train 20% is automatcally chose by python. since the train and test set have overlap its ok to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = []\n",
    "scale=0.6\n",
    "for img in X_train:\n",
    "    img_resize = cv2.resize(img, (0, 0), fx=scale, fy=scale)\n",
    "    gray = cv2.cvtColor(img_resize, cv2.COLOR_BGR2GRAY)\n",
    "    X_train_t.append(gray)\n",
    "X_train = X_train_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = []\n",
    "for img in X:\n",
    "    img_resize = cv2.resize(img, (0, 0), fx=scale, fy=scale)    \n",
    "    gray = cv2.cvtColor(img_resize, cv2.COLOR_BGR2GRAY)\n",
    "    X_t.append(gray)\n",
    "X = X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4-block\n",
    "width = X_train[0].shape[0]\n",
    "height = X_train[0].shape[1]\n",
    "X_train = np.asarray(X_train).astype('float32') / 255.\n",
    "X = np.asarray(X).astype('float32') / 255.\n",
    "X_train = np.reshape(X_train, (len(X_train), width, height, 1))  \n",
    "X = np.reshape(X, (len(X), width, height, 1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5th block\n",
    "y_train = pd.get_dummies(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate, X_test, y_validate, y_test = train_test_split(X, y, test_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# your comments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Training (max 12 pts)\n",
    "## Part 2.a - create and train a  working CNN (10/10 pts)\n",
    "use Keras: with Convolutional and Pooling operations and a dense sub network at the end, use properly the preprocessed portions of the dataset (train and validation) and apply scaling.\n",
    "\n",
    "## Part 2.b -  save the learned model (2/10 pts)\n",
    "save the model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for Part 2 - Training\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(width, height, 1)) \n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(16, activation='softmax')(x)\n",
    "model = Model(input_img, x)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 120, 120, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 120, 120, 16)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 60, 60, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 60, 60, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 30, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 7200)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                115216    \n",
      "=================================================================\n",
      "Total params: 116,536\n",
      "Trainable params: 116,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6379 samples, validate on 1275 samples\n",
      "Epoch 1/20\n",
      "6379/6379 [==============================] - 89s 14ms/step - loss: 1.7066 - acc: 0.4676 - val_loss: 0.8399 - val_acc: 0.6549\n",
      "Epoch 2/20\n",
      "6379/6379 [==============================] - 89s 14ms/step - loss: 0.6824 - acc: 0.7413 - val_loss: 0.6471 - val_acc: 0.7490\n",
      "Epoch 3/20\n",
      "6379/6379 [==============================] - 79s 12ms/step - loss: 0.5353 - acc: 0.8066 - val_loss: 0.4914 - val_acc: 0.8196\n",
      "Epoch 4/20\n",
      "6379/6379 [==============================] - 88s 14ms/step - loss: 0.4525 - acc: 0.8298 - val_loss: 0.4479 - val_acc: 0.8267\n",
      "Epoch 5/20\n",
      "6379/6379 [==============================] - 89s 14ms/step - loss: 0.3951 - acc: 0.8519 - val_loss: 0.3565 - val_acc: 0.8675\n",
      "Epoch 6/20\n",
      "6379/6379 [==============================] - 87s 14ms/step - loss: 0.3605 - acc: 0.8628 - val_loss: 0.3404 - val_acc: 0.8761\n",
      "Epoch 7/20\n",
      "6379/6379 [==============================] - 93s 15ms/step - loss: 0.3352 - acc: 0.8726 - val_loss: 0.3259 - val_acc: 0.8761\n",
      "Epoch 8/20\n",
      "6379/6379 [==============================] - 90s 14ms/step - loss: 0.3034 - acc: 0.8874 - val_loss: 0.2705 - val_acc: 0.9145\n",
      "Epoch 9/20\n",
      "6379/6379 [==============================] - 90s 14ms/step - loss: 0.2618 - acc: 0.9017 - val_loss: 0.3056 - val_acc: 0.8808\n",
      "Epoch 10/20\n",
      "6379/6379 [==============================] - 93s 15ms/step - loss: 0.2585 - acc: 0.9016 - val_loss: 0.2865 - val_acc: 0.8965\n",
      "Epoch 11/20\n",
      "6379/6379 [==============================] - 94s 15ms/step - loss: 0.2441 - acc: 0.9053 - val_loss: 0.2500 - val_acc: 0.8973\n",
      "Epoch 12/20\n",
      "6379/6379 [==============================] - 89s 14ms/step - loss: 0.2302 - acc: 0.9122 - val_loss: 0.2147 - val_acc: 0.9216\n",
      "Epoch 13/20\n",
      "6379/6379 [==============================] - 89s 14ms/step - loss: 0.2025 - acc: 0.9248 - val_loss: 0.1981 - val_acc: 0.9302\n",
      "Epoch 14/20\n",
      "6379/6379 [==============================] - 94s 15ms/step - loss: 0.1841 - acc: 0.9298 - val_loss: 0.1761 - val_acc: 0.9404\n",
      "Epoch 15/20\n",
      "6379/6379 [==============================] - 84s 13ms/step - loss: 0.1740 - acc: 0.9317 - val_loss: 0.2189 - val_acc: 0.9145\n",
      "Epoch 16/20\n",
      "6379/6379 [==============================] - 88s 14ms/step - loss: 0.1697 - acc: 0.9373 - val_loss: 0.1538 - val_acc: 0.9475\n",
      "Epoch 17/20\n",
      "6379/6379 [==============================] - 86s 13ms/step - loss: 0.1612 - acc: 0.9385 - val_loss: 0.1738 - val_acc: 0.9365\n",
      "Epoch 18/20\n",
      "6379/6379 [==============================] - 90s 14ms/step - loss: 0.1392 - acc: 0.9514 - val_loss: 0.1670 - val_acc: 0.9341\n",
      "Epoch 19/20\n",
      "6379/6379 [==============================] - 84s 13ms/step - loss: 0.1337 - acc: 0.9514 - val_loss: 0.1357 - val_acc: 0.9514\n",
      "Epoch 20/20\n",
      "6379/6379 [==============================] - 89s 14ms/step - loss: 0.1208 - acc: 0.9591 - val_loss: 0.1263 - val_acc: 0.9569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a456b28b70>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          shuffle=True,\n",
    "          validation_data=(X_validate, y_validate),\n",
    "          callbacks=[TensorBoard(log_dir='/tmp/model', histogram_freq=0, write_graph=True)]\n",
    "         )          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('shadiandishmandmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# your comments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 2\n",
    "validation set was was a part of train set so we predict that the val_accuracy will be something near the 1. we tried many numbers of epoches so finally i decieded to put it 20 epoches which give me about 90% accuracy.\n",
    "\n",
    "we put some of the hyperparameters like activation functions,batch_size,and etc of the network and made a CNN, with input layer to be appropriate for images and a dense layer with softmax at the output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Evaluation (max 10 pts)\n",
    "## Part 3.a - Test (max 8/10 pts)\n",
    "- use the classifier built during Part 2, to classify the lego brick label of each picture of your Test dataset portion.\n",
    "- print the classifcation report\n",
    "\n",
    "## Part 3.b - minal f1 requirement (max 2/10 pts)\n",
    "- if from the report (in part 3.a) you printed, the weighted avg F1 is greater than 0.60 you get 1 point\n",
    "- if from the report (in part 3.a) you printed, the weighted avg F1 is greater than 0.70 you get 1 point\n",
    "- if from the report you printed in part 3.a the weighted avg F1 is less or equal to 0.60 you get -2 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for  part 3\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('shadiandishmandmodel.h5')\n",
    "model = Model(inputs=model.input, outputs=model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "l_pred = []\n",
    "for p in pred:\n",
    "    l_pred.append(np.argmax([int(round(x)) for x in p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_l = []\n",
    "for p in np.asarray(y_test):\n",
    "    y_test_l.append(np.argmax(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       324\n",
      "           1       0.88      0.95      0.91       320\n",
      "           2       1.00      1.00      1.00       309\n",
      "           3       1.00      1.00      1.00       333\n",
      "           4       1.00      1.00      1.00       324\n",
      "           5       1.00      1.00      1.00       324\n",
      "           6       1.00      1.00      1.00       327\n",
      "           7       0.83      0.91      0.87       319\n",
      "           8       0.99      1.00      1.00       319\n",
      "           9       1.00      0.99      1.00       310\n",
      "          10       1.00      0.98      0.99       310\n",
      "          11       1.00      1.00      1.00       310\n",
      "          12       0.99      0.90      0.94       336\n",
      "          13       1.00      1.00      1.00       313\n",
      "          14       0.91      0.72      0.81       313\n",
      "          15       1.00      1.00      1.00       313\n",
      "\n",
      "    accuracy                           0.96      5104\n",
      "   macro avg       0.96      0.96      0.96      5104\n",
      "weighted avg       0.96      0.96      0.96      5104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_l, l_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# your comments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 3\n",
    "\n",
    "i imported keras.models and sklearn.metrics to load model and make classification report.with classification report when i give it the correct target values and those how predicted by CNN it displays the precision, recall, F1, and support scores for the each class so as i predicted it give about 96 accuracy avg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Feature importance (max 2/30 pts)\n",
    "## Part 4.a perform a pixel based feature importance analysis on the validation portion of the dataset (1 pts)\n",
    "## Part 4.b plot the corresponding heatmap of pixel importance (1 pts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for part 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 3\n",
    "forest = ExtraTreesClassifier(n_estimators=1000,\n",
    "                              n_jobs=n_jobs,\n",
    "                              verbose=1,\n",
    "                              criterion='entropy',\n",
    "                              random_state=0)\n",
    "\n",
    "X_validate = X_validate.reshape((len(X_validate), width*height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:   28.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
       "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=3,\n",
       "                     oob_score=False, random_state=0, verbose=1,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = forest.feature_importances_\n",
    "importances = importances.reshape((width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(importances, cmap=plt.cm.hot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# your comments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 4\n",
    "feature importance provides a score that indicates how each feature was valueable in the construction of the boosted decision trees\n",
    "within my model.The more an attribute is used to make key decisions in decision trees, the higher its relative importance so this informations gain from\n",
    "each pixel in my model after fit it. the higher information give us brighter resoloution in that pixels in the feature importance image.\n",
    "\n",
    "The heat map that we get is not very good.it is black at the borders.The images are almost are all in grayscale, so we get that the center is darker that than the circles around it because the defining edges are spread around it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 - Extra point\n",
    "- if from the report you printed in part 3.a the weighted avg F1 is greater tha 0.85 you get 1 point\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"dexter.jpg\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
